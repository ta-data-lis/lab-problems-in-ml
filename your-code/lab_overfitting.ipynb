{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting\n",
    "## In this lab, we are going to explore how thoughtfully choosing a model and using test set are important parts of avoiding overfitting. \n",
    "\n",
    "We are going to apply these concepts to a classification model. We want to develop a decision boundary, on one side of which we have class A and on the other we have class B.\n",
    "\n",
    "Like we disussed in class, when we have noisy data, if we are not careful, we can end up fitting our model to the noise in the data and not the 'signal'-- the factors that actually determine the outcome. This is called overfitting, and results in good results in training, and in bad results when the model is applied to real data. Similarly, we could have a model that is too simplistic to accurately model the signal. This produces a model that doesnt work well (ever), and sucks only slightly less than overfitting. At least your model performs consistently bad :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we are going to generate some synthetic data. To make these concepts visual, we are going to generate this data to be concentric circles. Run the code below to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Makin' some data\n",
    "from sklearn.datasets import make_circles\n",
    "X, y = make_circles(noise=0.2, factor=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As our classification algorithm, we are going to use a type of SVM with a radial basis function. This basically works by mapping each point into a higher dimensional space that can be split by the SVM (gross oversimplificaiton). That looks something like this:\n",
    "![RBFSVM.png](../images/RBFSVM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can change thecomplexity of the decision boundaries applied by the SVM by changignt the size of the radial basis function, through the parameter 'gamma'.\n",
    "\n",
    "Instantiate a list of three SVM classifiers with three different gamma parameters, (.001, 1, and 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "x = SVC(gamma=0.001)\n",
    "y = SVC(gamma=1)\n",
    "z = SVC(gamma=20)\n",
    "\n",
    "classifiers = [x, y, z]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we are going to plot the boundaries created by each of these classifiers with the points we generated. Run the following code to make three graphs of each SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape ()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-01d93dbaecfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Plot the decision boundary. For that, we will assign a color to each\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    144\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[0;32m    145\u001b[0m                          \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m                          accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    722\u001b[0m                         dtype=None)\n\u001b[0;32m    723\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    725\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'O'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    758\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bad input shape {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: bad input shape ()"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "figure = plt.figure(figsize=(12, 6))\n",
    "i = 1\n",
    "h = .02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    ax = plt.subplot(1, len(classifiers), i)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    else:\n",
    "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap=cm_bright)\n",
    "\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(name)\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where the contour is red, we will predict red, and same for blue; white means there is a 50/50 chance of either class\n",
    "Explain what you see in the plots above.\n",
    "\n",
    "Which gamma do you think fits the data best? \n",
    "\n",
    "What would you select as the opitmal gamma?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your response here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without having used a training and testing set, lets see what our accuracy score would be for, for example, a gamma of .7. Use the .score() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wow thats good accuracy! But is it generalizable? Make a test/train split and see how the model performs on the SVM with the gamma of 20. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with some of the other gammas to see how the accuracy score changes after implementing a test/train split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Was your previous model overfitting? If so, how would you try to improve this model to prevent this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your response here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
